# ğŸ‘¨â€ğŸ’» Dokumentacja Techniczna (Wersja Rozszerzona)

Ten dokument stanowi szczegÃ³Å‚owy przewodnik po kodzie ÅºrÃ³dÅ‚owym projektu **AI Play Games**. Jest przeznaczony dla programistÃ³w chcÄ…cych zrozumieÄ‡ "co dzieje siÄ™ pod maskÄ…".

---

## ğŸ— Architektura Systemu

Projekt oparty jest na bibliotece **Stable Baselines3** (SB3), ktÃ³ra dostarcza gotowe implementacje algorytmÃ³w Reinforcement Learning (RL). UÅ¼ywamy **Gymnasium** jako standardu Å›rodowisk gier.

CaÅ‚oÅ›Ä‡ spiÄ™ta jest przez centralny punkt wejÅ›cia (`main.py`) i konfiguracjÄ™ w JSON.

### PrzepÅ‚yw danych (Data Flow)
1.  **Start**: `run.sh` uruchamia `main.py` z odpowiednimi flagami.
2.  **Konfiguracja**: `main.py` czyta `config.json` aby ustaliÄ‡ parametry (gra, algorytm, czas uczenia).
3.  **Trening**: `train.py` tworzy Å›rodowisko gry i agenta (Model), a nastÄ™pnie startuje pÄ™tlÄ™ uczenia.
4.  **Logowanie**: Podczas treningu, SB3 zapisuje metryki (TensorBoard) do folderu `logs/`.
5.  **Ewaluacja & Zapis**: Callbacki co pewien czas testujÄ… model. Najlepszy wynik jest zapisywany w `models/`.
6.  **Analiza**: Po treningu `plot.py` czyta logi i generuje wykresy `.png`.

---

## ğŸ“‚ SzczegÃ³Å‚owa Analiza PlikÃ³w

### 1. `src/stable_baseline/main.py` (Entry Point)

Jest to gÅ‚Ã³wny sterownik aplikacji (Controller). Nie zawiera logiki biznesowej, a jedynie logikÄ™ sterujÄ…cÄ….

**Kluczowe fragmenty:**
-   **`argparse`**: Definiuje dostÄ™pne polecenia CLI (`--mode`, `--env`, `--algo`). Pozwala nadpisywaÄ‡ ustawienia z pliku config z poziomu terminala.
-   **Åadowanie Configu**: Funkcja `load_config` wczytuje plik JSON. JeÅ›li podamy argumenty CLI, majÄ… one pierwszeÅ„stwo przed JSON-em.
-   **Routing**: Blok `if args.mode == ...` decyduje, ktÃ³rÄ… funkcjÄ™ uruchomiÄ‡:
    -   `train`: Uruchamia `train.py`.
    -   `visualize`: Uruchamia `visualize.py`.
    -   `plot`: Uruchamia `plot.py`.
    -   `optimize`: Uruchamia `optimize.py` (Optuna).

### 2. `src/stable_baseline/utils/train.py` (Trening)

To najwaÅ¼niejszy plik w projekcie. Odpowiada za konfiguracjÄ™ i uruchomienie procesu uczenia.

**GÅ‚Ã³wne funkcje:**
-   **`train(...)`**: Ta funkcja spina wszystko w caÅ‚oÅ›Ä‡.
    1.  **Tworzenie Å›rodowiska**: `make_vec_env` tworzy instancjÄ™ gry. UÅ¼ywamy `DummyVecEnv`, co jest standardem w SB3 (nawet dla jednej gry Å›rodowisko jest "wektoryzowane", czyli opakowane w listÄ™).
    2.  **Inicjalizacja Agenta**: Na podstawie `ALGO_MAP` (sÅ‚ownik mapujÄ…cy nazwy na klasy np. `PPO`, `DQN`) tworzony jest obiekt algorytmu.
    3.  **Hiperparametry**: JeÅ›li podano `hyperparams` (np. z optymalizacji), domyÅ›lne ustawienia (learning rate, gamma) sÄ… nadpisywane.
    4.  **Callbacki**:
        -   `EvalCallback`: Odpala osobne Å›rodowisko (`eval_env`) co X krokÃ³w, by sprawdziÄ‡ jak model sobie radzi bez szumu eksploracji. To on zapisuje `best_model.zip`.

**WaÅ¼ne koncepty**:
-   **Policy**: `MlpPolicy` to sieÄ‡ neuronowa operujÄ…ca na liczbach (np. pozycja wÃ³zka). `CnnPolicy` to sieÄ‡ konwolucyjna (do obrazÃ³w), uÅ¼ywana np. w `CarRacing`.
-   **Wrapper**: Dla DQN w CarRacing uÅ¼ywamy `DiscreteActionsWrapper`, bo DQN nie obsÅ‚uguje ciÄ…gÅ‚ego sterowania (kierownica -1.0 do 1.0), wiÄ™c musimy je zamieniÄ‡ na dyskretne (lewo, prawo, gaz).

### 3. `src/stable_baseline/visualization/plot.py` (Wykresy)

Odpowiada za wizualizacjÄ™ postÄ™pÃ³w. Nie korzysta z `tensorboard` w przeglÄ…darce, ale generuje statyczne obrazki `.png` do raportÃ³w.

**Jak to dziaÅ‚a:**
1.  Skrypt szuka plikÃ³w `events.out.tfevents...` w katalogu `logs/`. SÄ… to binarne pliki zapisu protokoÅ‚u Protocol Buffers uÅ¼ywane przez TensorBoard.
2.  `EventAccumulator`: Klasa z biblioteki TensorFlow/TensorBoard, ktÃ³ra parsuje te pliki.
3.  **Ekstrakcja danych**: WyciÄ…gamy tagi takie jak `rollout/ep_rew_mean` (Å›rednia nagroda w epizodzie) lub `train/loss`.
4.  **Seaborn/Matplotlib**: Dane trafiajÄ… do biblioteki graficznej, ktÃ³ra rysuje wykresy liniowe porÃ³wnujÄ…ce rÃ³Å¼ne algorytmy.

### 4. `src/stable_baseline/optimize.py` (Optymalizacja)

Ten moduÅ‚ uÅ¼ywa biblioteki **Optuna** do automatycznego szukania najlepszych parametrÃ³w (Hyperparameter Tuning).

**Logika:**
-   **`objective(trial)`**: To funkcja celu. Optuna "wymyÅ›la" zestaw parametrÃ³w (np. `learning_rate=0.001`), uruchamia trening (`train()`) i zwraca uzyskany wynik (nagrodÄ™).
-   **Przetrzesz**: Optuna na podstawie historii prÃ³b zgaduje, jakie parametry mogÄ… daÄ‡ lepszy wynik w kolejnej prÃ³bie (uÅ¼ywa estymatora TPE - Tree-structured Parzen Estimator).
-   Wyniki sÄ… zapisywane w bazie SQLite (`optuna.db`) oraz jako plik JSON (`best_params.json`), ktÃ³ry potem moÅ¼e byÄ‡ uÅ¼yty przez `main.py` i `train.py`.

### 5. `src/stable_baseline/visualization/visualize.py` (PodglÄ…d)

SÅ‚uÅ¼y do "oglÄ…dania" jak gra nauczony model.

**Kluczowa pÄ™tla:**
```python
while not done:
    action, _ = model.predict(obs, deterministic=True) # Zapytaj model o akcjÄ™
    obs, reward, terminated, truncated, info = env.step(action) # Wykonaj akcjÄ™ w grze
```
ZwrÃ³Ä‡ uwagÄ™ na `deterministic=True`. Podczas treningu model czasem losuje akcje (eksploracja), ale podczas testÃ³w/pokazu chcemy, by graÅ‚ najlepiej jak umie, wiÄ™c wyÅ‚Ä…czamy losowoÅ›Ä‡.

---

## ğŸ›  Rozszerzanie Projektu (Poradnik)

### Jak dodaÄ‡ nowy algorytm (np. SAC)?
1.  Zaimportuj go w `utils/train.py`: `from stable_baselines3 import SAC`.
2.  Dodaj do sÅ‚ownika `ALGO_MAP` w `train.py` i `visualize.py`.
3.  PamiÄ™taj, Å¼e SAC dziaÅ‚a tylko z ciÄ…gÅ‚Ä… przestrzeniÄ… akcji (jak CarRacing), a nie dyskretnÄ… (jak CartPole), chyba Å¼e uÅ¼yjesz specjalnego wrappera.

### Jak zmieniÄ‡ architekturÄ™ sieci neuronowej?
W `train.py` modyfikujemy zmiennÄ… `net_arch`.
-   `[64, 64]` oznacza dwie warstwy ukryte po 64 neurony.
-   MoÅ¼esz to zmieniÄ‡ w `setup` modelu, w argumencie `policy_kwargs`.

### Debugowanie problemÃ³w z treningiem
JeÅ›li model siÄ™ nie uczy (wykres jest pÅ‚aski):
1.  SprawdÅº `learning_rate` (moÅ¼e byÄ‡ za duÅ¼y lub za maÅ‚y).
2.  SprawdÅº `ent_coef` (parametr entropii - jeÅ›li jest za maÅ‚y, model za szybko "zdecyduje" Å¼e znalazÅ‚ rozwiÄ…zanie i przestanie prÃ³bowaÄ‡ nowych rzeczy).
3.  ZwiÄ™ksz `n_steps` lub `batch_size`.
